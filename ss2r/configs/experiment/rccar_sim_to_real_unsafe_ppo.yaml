# @package _global_
defaults:
  - override /environment: rccar_real
  - override /agent: ppo
  - override /agent/penalizer: null
  - _self_

environment:
  action_delay: 1
  observation_delay: 0
  sliding_window: 5
  dt: 0.03333333
  sample_init_pose: true
  init_pose: [1.42, -1.04, -3.142]

training:
  num_envs: 4096
  num_timesteps: 250000000
  episode_length: 250
  train_domain_randomization: true
  eval_domain_randomization: true
  safe: false

agent:
  batch_size: 256
  discounting: 0.97
  entropy_cost: 0.01
  learning_rate: 0.0003
  max_grad_norm: 1.0
  policy_hidden_layer_sizes: [64, 64]
  value_hidden_layer_sizes: [64, 64]
  normalize_observations: true
  num_minibatches: 32
  num_resets_per_eval: 1
  num_updates_per_batch: 4
  reward_scaling: 1.0
  unroll_length: 20
  activation: swish
