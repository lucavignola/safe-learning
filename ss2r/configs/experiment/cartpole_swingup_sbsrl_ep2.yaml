# @package _global_
defaults:
  - override /environment: cartpole_swingup
  - override /agent: sbsrl
  - override /agent/data_collection: episodic
  - override /agent/penalizer: multiaug_lagrangian
  - _self_

training:
  num_timesteps: 2500000
  action_repeat: 4
  safe: true
  train_domain_randomization: false
  eval_domain_randomization: false
  safety_budget: 100
  num_envs: 20
  num_evals: 15
  num_eval_episodes: 10
  wandb_id: tjabwpzf #,4ne87e1s,651uyrm2,ytjenkjh,10yjpvr3

agent:
  policy_hidden_layer_sizes: [256, 256, 256]
  value_hidden_layer_sizes: [512, 512]
  activation: swish
  batch_size: 256
  min_replay_size: 8192 #1000
  max_replay_size: 1548576
  critic_grad_updates_per_step: 2000
  model_grad_updates_per_step: 80000
  num_model_rollouts: 100000
  learning_rate: 3e-4
  critic_learning_rate: 3e-4
  model_learning_rate: 3e-4
  uncertainty_constraint: true
  uncertainty_epsilon: 0.0
  use_mean_critic: false
  separate_critics: true
  model_to_real_data_ratio: 1
  optimistic_qr: true
  penalizer:
    lagrange_multiplier: 2.5
    penalty_multiplier: 1e-3
    penalty_multiplier_factor: 1e-4
    lagrange_multiplier_sigma: 0

